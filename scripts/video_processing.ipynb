{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a9062c",
   "metadata": {},
   "source": [
    "# THE PLAN\n",
    "1. A function, that will accept minio url\n",
    "2. Download the video from minio to a temp directory\n",
    "3. Extract Audio\n",
    "4. Load OpenAI's Whisper model\n",
    "5. Covert Audio to Text\n",
    "6. append .srt artifacts,i.e, every sentence is a new line and has timestamps (maybe?)\n",
    "7. Upload the .srt file to minio\n",
    "8. Use the text to generate summary, and chapters for the video\n",
    "9. Summary can be stored in DB as video.description (so 2 things,1> pass the video id & 2> move DB to PG or smthing)\n",
    "10. IDK how to store the chapters, maybe in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df835a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install minio openai-whisper ffmpeg-python ollama SQLAlchemy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_IP=\"192.168.0.118\"\n",
    "MINIO_PORT=\"9010\"\n",
    "MINIO_ACCESS_KEY=\"oloom_key\"\n",
    "MINIO_SECRET_KEY=\"KhGjEmfDW07wMN34SYKJkv539o7Rfq8yoGK0efeS\"\n",
    "OLLAMA_URL=\"https://ollama.homelab.subhranshu.com\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "import shutil\n",
    "from minio import Minio\n",
    "import os\n",
    "import whisper\n",
    "import ffmpeg\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import Session, DeclarativeBase\n",
    "from pathlib import Path\n",
    "from ollama import Client\n",
    "\n",
    "class Base(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self,video_id,file_name):\n",
    "        NOTEBOOK_DIR = Path().resolve() \n",
    "        BASE_DIR = NOTEBOOK_DIR.parent   \n",
    "        DB_PATH = os.path.join(BASE_DIR, \"web\", \"db.sqlite\")\n",
    "        SQLITE_URL = f\"sqlite:///{DB_PATH}\"\n",
    "\n",
    "        engine = create_engine(SQLITE_URL)\n",
    "        Base.metadata.create_all(engine)\n",
    "\n",
    "        temp_dir = mkdtemp(prefix=f\"oloom_\")\n",
    "\n",
    "        print(f\"Temp dir: {temp_dir}\")\n",
    "        print(f\"Temp video path: {temp_dir}/{file_name}\")\n",
    "\n",
    "        self.video_id = video_id\n",
    "        self.file_name = file_name\n",
    "        self.temp_dir = temp_dir\n",
    "        self.video_path = f\"{temp_dir}/{file_name}\"\n",
    "        self.minio_client = Minio(\n",
    "            f\"{MINIO_IP}:{MINIO_PORT}\",\n",
    "            access_key=MINIO_ACCESS_KEY,\n",
    "            secret_key=MINIO_SECRET_KEY,\n",
    "            secure=False\n",
    "        )\n",
    "        self.model = whisper.load_model(\"turbo\")\n",
    "        self.ollama_client = Client(host=OLLAMA_URL)\n",
    "        self.db = engine\n",
    "\n",
    "\n",
    "        if not self.minio_client.bucket_exists(\"oloom\"):\n",
    "            raise Error(\"Minio bucket does not exist\")\n",
    "        \n",
    "        self.download_video()\n",
    "        self.extract_audio()\n",
    "        combined_text = self.transcribe()\n",
    "        summary_text = self.summarize(combined_text)\n",
    "        self.update_db(summary_text)\n",
    "        self.upload_vtt()\n",
    "        self.cleanup()\n",
    "\n",
    "    def download_video(self):\n",
    "        try:\n",
    "            self.minio_client.fget_object(bucket_name=\"oloom\",object_name=self.file_name,file_path=self.video_path)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading video: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def extract_audio(self):\n",
    "        try:\n",
    "            audio = ffmpeg.input(self.video_path)\n",
    "            audio = ffmpeg.output(audio, f\"{self.temp_dir}/output.wav\", acodec=\"pcm_s16le\", ac=1, ar=\"16k\",loglevel=\"quiet\")\n",
    "            ffmpeg.run(audio, overwrite_output=True)\n",
    "            print(f\"Audio path: {self.temp_dir}/output.wav\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting audio: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def transcribe(self):\n",
    "        def format_timestamp(seconds: float, always_include_hours: bool = False, fractionalSeperator: str = '.'):\n",
    "            assert seconds >= 0, \"non-negative timestamp expected\"\n",
    "            milliseconds = round(seconds * 1000.0)\n",
    "\n",
    "            hours = milliseconds // 3_600_000\n",
    "            milliseconds -= hours * 3_600_000\n",
    "\n",
    "            minutes = milliseconds // 60_000\n",
    "            milliseconds -= minutes * 60_000\n",
    "\n",
    "            seconds = milliseconds // 1_000\n",
    "            milliseconds -= seconds * 1_000\n",
    "\n",
    "            hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
    "            return f\"{hours_marker}{minutes:02d}:{seconds:02d}{fractionalSeperator}{milliseconds:03d}\"\n",
    "\n",
    "        try:\n",
    "            audio_path = f\"{self.temp_dir}/output.wav\"\n",
    "            start_time = time.time()\n",
    "            result = self.model.transcribe(audio_path,verbose=True)\n",
    "            print(f\"Time taken for transcription: {time.time() - start_time:.2f} seconds\")\n",
    "            segments = result[\"segments\"]\n",
    "            combined_text = result[\"text\"]\n",
    "            srt_path = f\"{self.temp_dir}/transcript.vtt\"\n",
    "\n",
    "            with open(srt_path, \"w\", encoding='utf-8') as f:\n",
    "                f.write(\"WEBVTT\\n\\n\")\n",
    "                for segment in tqdm(segments, total=len(segments), desc=\"Writing VTT\"):\n",
    "                    text = segment['text'].strip().replace('-->', '->')\n",
    "                    \n",
    "                    f.write(\n",
    "                        f\"{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])}\\n\"\n",
    "                        f\"{text}\\n\\n\"\n",
    "                    )\n",
    "\n",
    "            print(f\"VTT file: {srt_path}\")\n",
    "            return combined_text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error transcribing video: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def summarize(self,text):\n",
    "        try:\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\": f\"You are a helpful assistant. Summarize the following text in a concise manner. Avoid including intro text. \\n\\n{text}\"\n",
    "                }\n",
    "            ]\n",
    "            model = 'llama3.2:3b'\n",
    "            response = self.ollama_client.chat(model=model, messages=messages)\n",
    "            return response['message']['content']\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing text: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def update_db(self,summary_text):\n",
    "        try:\n",
    "            with Session(self.db) as session:\n",
    "                # Query all videos with their associated users\n",
    "                sql_query = \"UPDATE web_video SET description=:summary WHERE id=:id\"\n",
    "                session.execute(text(sql_query), {'summary': summary_text, 'id': self.video_id})\n",
    "                session.commit()\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating database: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def upload_vtt(self):\n",
    "        try:\n",
    "            vtt_object_name = f\"{\"/\".join(self.file_name.split(\"/\")[0:-1])}/transcript.vtt\"\n",
    "            vtt_path = f\"{self.temp_dir}/transcript.vtt\"\n",
    "            txt_path = f\"{self.temp_dir}/transcript.txt\"\n",
    "            self.minio_client.fput_object(bucket_name=\"oloom\",object_name=vtt_object_name,file_path=vtt_path,content_type=\"text/vtt\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading SRT: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def cleanup(self):\n",
    "        print(f\"Cleaning up: {self.temp_dir}\")\n",
    "        shutil.rmtree(self.temp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066d4c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp dir: /var/folders/b9/x0sm9z492qd6qs1dyjpcyydw0000gn/T/oloom_3_35lvpx\n",
      "Temp video path: /var/folders/b9/x0sm9z492qd6qs1dyjpcyydw0000gn/T/oloom_3_35lvpx/5fbb04c0-45bb-457e-8470-03eb6a8e314e/adf94035-ccca-460f-a7f6-6e172b631ef4/video.mp4\n",
      "Audio path: /var/folders/b9/x0sm9z492qd6qs1dyjpcyydw0000gn/T/oloom_3_35lvpx/output.wav\n",
      "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subhr/Documents/GitHub/temp/oloom/scripts/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: English\n",
      "[00:00.000 --> 00:07.740]  Yesterday, after achieving a, quote, ludicrous rate of progress, Elon Musk released his AI chatbot in large language model, Grok4,\n",
      "[00:07.860 --> 00:12.320]  and claims it's the smartest AI in the world, along with the Trust Me Bro benchmarks to back it up.\n",
      "[00:12.380 --> 00:18.020]  It can achieve perfect SAT scores every time, and outperforms almost every grad student in every discipline.\n",
      "[00:18.300 --> 00:23.780]  Vibe coders have been dropping all kinds of crazy demos with it, like this 3D first-person shooter built in four hours,\n",
      "[00:24.040 --> 00:29.300]  and Elon himself claims it's even better than Cursor. All you have to do is copy and paste your entire codebase into it.\n",
      "[00:29.300 --> 00:33.500]  In addition, Super Grok4 Heavy can run in parallel to solve complex problems,\n",
      "[00:33.640 --> 00:37.280]  while your obsolete monkey brain looks in awe at this beautiful futuristic UI.\n",
      "[00:37.740 --> 00:42.080]  It all sounds amazing, but there's just one problem. Grok is literally MechaHitler,\n",
      "[00:42.180 --> 00:48.060]  or at least that's what it's been calling itself recently, while offering unprompted praise to the original emo kid Adolf H.\n",
      "[00:48.220 --> 00:51.380]  Yes, the Austrian painter who died in Argentina in 1962.\n",
      "[00:51.760 --> 00:55.940]  Despite this controversy, though, Grok appears to have pulled ahead in the race to AGI.\n",
      "[00:55.940 --> 01:02.300]  In today's video, we'll put it to the ultimate test and find out if XAI just cracked the final solution to artificial intelligence.\n",
      "[01:02.620 --> 01:05.940]  It is July 11th, 2025, and you're watching The Code Report.\n",
      "[01:06.160 --> 01:09.460]  Elon Musk might have more haters than anyone else in the world right now.\n",
      "[01:09.720 --> 01:14.940]  Libs hate him for going full MAGA, while MAGA hates him for accusing Trump of being on the Epstein client list,\n",
      "[01:15.180 --> 01:18.840]  a list that was on the Attorney General's desk, but now magically never existed.\n",
      "[01:19.220 --> 01:22.400]  It turns out this poor guy was just a math teacher with no clients at all.\n",
      "[01:22.400 --> 01:26.140]  The haters want to see Elon fail, but Grok 4 is too impressive to ignore.\n",
      "[01:26.400 --> 01:31.060]  If we're to trust these benchmarks, its reasoning capabilities are far ahead of the other top models.\n",
      "[01:31.320 --> 01:37.460]  Most notably, on the ARC AGI benchmark, it's not only outperforming other models, but also doing it at a lower cost.\n",
      "[01:37.580 --> 01:44.620]  And XAI is scaling up very aggressively, like they're even shipping a power plant from overseas because they can't get it done fast enough in the United States.\n",
      "[01:44.620 --> 01:48.820]  The thing is though, every model nowadays is cooked to look as good as possible on benchmarks.\n",
      "[01:49.140 --> 01:52.400]  And the one true test is to have it solve real problems in your own life.\n",
      "[01:52.560 --> 01:58.960]  You can use Grok 4 for just $30 per month, or if you're not already broke from OpenAI Pro, Claude Max, and Gemini Ultra,\n",
      "[01:59.280 --> 02:06.520]  you can use Super Grok 4 Heavy for just $300 per month, a version with higher rate limits and the ability to run multiple agents in parallel.\n",
      "[02:06.780 --> 02:09.940]  But one problem in my life is building Svelte 5 apps with runes.\n",
      "[02:10.040 --> 02:13.700]  So let's see if we can make Grok 4 build a simple to-do app with this tech.\n",
      "[02:13.700 --> 02:17.880]  I've tried this prompt with every other AI tool out there, but none have been able to satisfy me.\n",
      "[02:18.060 --> 02:20.020]  When prompted, Grok did a ton of research.\n",
      "[02:20.180 --> 02:24.160]  It went to the documentation, it went to Reddit, GitHub, and even watched YouTube videos.\n",
      "[02:24.340 --> 02:28.680]  And the end result was a full-working demo that did use the new runes feature in Svelte 5.\n",
      "[02:28.840 --> 02:35.020]  However, when I looked a little more closely at the code, I noticed it was using some legacy syntax that required some manual debugging.\n",
      "[02:35.340 --> 02:41.800]  Overall, Grok's coding capabilities seem to be on par with the other big models, but it's missing a CLI tool like ClaudeCode.\n",
      "[02:41.800 --> 02:45.840]  However, if it's as good as they say it is, why can't it just build its own CLI tool?\n",
      "[02:46.020 --> 02:48.600]  Well, actually it can, and that's exactly what this guy did.\n",
      "[02:48.700 --> 02:53.960]  If we're truly advancing into the singularity, AI can and should be building all of its own tooling at this point.\n",
      "[02:54.200 --> 03:00.160]  Pretty cool, but if you're still afraid to use it because of Hitler, you'll be happy to know that Elon said it was manipulated into saying this.\n",
      "[03:00.300 --> 03:01.640]  Maybe that's true, maybe not.\n",
      "[03:01.720 --> 03:06.600]  But in general, Grok has far fewer guardrails on offensive speech compared to other mainstream models.\n",
      "[03:06.600 --> 03:11.140]  And this gives the end user the ability to steer it in unique ways that some might find offensive.\n",
      "[03:11.520 --> 03:16.980]  AI is now writing more of our code than ever, but according to a recent Microsoft study, it still sucks at debugging.\n",
      "[03:17.180 --> 03:20.160]  Which is why you should check out Sentry, the sponsor of today's video.\n",
      "[03:20.400 --> 03:28.180]  They just launched a new AI debugging agent called Sear, which developers claim is actually good and capable of fixing complex issues in one shot.\n",
      "[03:28.180 --> 03:40.460]  That's because unlike other AI debugging tools, Sear can access all of the context that it gets from your code base, like error data, logs, and stack traces, allowing it to pinpoint the root cause with over 94% accuracy.\n",
      "[03:40.700 --> 03:46.340]  Using this context, it automatically debugs the root cause of your issue and opens a pull request with a fix.\n",
      "[03:46.440 --> 03:50.200]  Try out Sear for free today at sentry.io slash fireship.\n",
      "[03:50.360 --> 03:53.920]  This has been the Code Report, thanks for watching, and I will see you in the next one.\n",
      "Time taken for transcription: 42.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing VTT: 100%|██████████| 47/47 [00:00<00:00, 435170.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTT file: /var/folders/b9/x0sm9z492qd6qs1dyjpcyydw0000gn/T/oloom_3_35lvpx/transcript.vtt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up: /var/folders/b9/x0sm9z492qd6qs1dyjpcyydw0000gn/T/oloom_3_35lvpx\n",
      "Time taken: 170.44099497795105\n"
     ]
    }
   ],
   "source": [
    "start_t = time.time()\n",
    "VideoProcessor = VideoProcessor(\n",
    "  \"7377ff6f-aa18-4e7c-bb24-4636bb04b511\",\n",
    "  \"5fbb04c0-45bb-457e-8470-03eb6a8e314e/adf94035-ccca-460f-a7f6-6e172b631ef4/video.mp4\"\n",
    ")\n",
    "end_t = time.time()\n",
    "print(f\"Time taken: {end_t - start_t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
